{
  "pageTitle": "AI Agent Code Examples",
  "pageDescription": "Explore practical code examples of AI Agents built with LangChain and LangGraph.",
  "examples": [
    {
      "id": "simple-chain",
      "title": "Simple LangChain Chain",
      "description": "A basic example of a LangChain chain that processes user input through a language model.",
      "difficulty": "Beginner",
      "tags": ["LangChain", "Chain", "LLM"],
      "code": {
        "language": "python",
        "content": "from langchain.prompts import PromptTemplate\nfrom langchain.llms import OpenAI\nfrom langchain.chains import LLMChain\n\n\n# Initialize the language model\nllm = OpenAI(temperature=0.7)\n\n# Create a prompt template\nprompt = PromptTemplate(\n    input_variables=[\"topic\"],\n    template=\"\"\"Write a short blog post about {topic}. \n    Make it engaging and informative.\"\"\"\n)\n\n# Create the chain\nchain = LLMChain(\n    llm=llm, \n    prompt=prompt\n)\n\n# Run the chain\nresult = chain.run(topic=\"AI Agents and their applications\")\nprint(result)",
        "explanation": "This example demonstrates a simple LangChain chain. It uses a prompt template to structure the input, passes it to an OpenAI language model, and returns the generated text. The temperature parameter (0.7) controls the randomness of the output - higher values produce more creative results."
      },
      "output": {
        "content": "# AI Agents and Their Applications\n\nIn the rapidly evolving landscape of artificial intelligence, AI agents have emerged as powerful tools that are transforming how we interact with technology. But what exactly are AI agents, and how are they being applied in the real world?\n\nAI agents are autonomous or semi-autonomous systems that can perceive their environment, make decisions, and take actions to achieve specific goals. Unlike traditional software, these agents can learn, adapt, and operate with minimal human supervision.\n\nThe applications of AI agents span across numerous industries:\n\n## Customer Service\nAI agents now handle customer inquiries through chatbots and virtual assistants, providing 24/7 support without human fatigue. Companies like Intercom and Drift have deployed sophisticated conversational agents that can resolve common issues and seamlessly hand off complex problems to human representatives.\n\n## Healthcare\nIn healthcare, AI agents assist with everything from appointment scheduling to preliminary diagnoses. They analyze patient symptoms, medical histories, and even medical images to provide decision support for healthcare professionals.\n\n## Finance\nFinancial institutions use AI agents for fraud detection, investment recommendations, and automated trading. These agents can process vast amounts of market data in milliseconds, identifying patterns and opportunities that human traders might miss.\n\n## Personal Productivity\nPersonal AI assistants like Siri, Alexa, and Google Assistant help manage schedules, answer questions, and control smart home devices. More advanced agents can even draft emails, summarize meetings, and prioritize tasks based on user preferences.\n\nAs AI technology continues to advance, we can expect these agents to become more capable, more intuitive, and more integrated into our daily lives. The future of AI agents lies not just in what they can do, but in how seamlessly they can collaborate with humans to enhance our capabilities and free us to focus on more creative and fulfilling work."
      }
    },
    {
      "id": "conversational-agent",
      "title": "Conversational Agent with Memory",
      "description": "A conversational agent that can remember previous interactions and maintain context throughout a conversation.",
      "difficulty": "Intermediate",
      "tags": ["LangChain", "Memory", "Conversation"],
      "code": {
        "language": "python",
        "content": "from langchain.memory import ConversationBufferMemory\nfrom langchain.llms import OpenAI\nfrom langchain.chains import ConversationChain\n\n\n# Initialize the language model\nllm = OpenAI(temperature=0.7)\n\n# Initialize memory\nmemory = ConversationBufferMemory()\n\n# Create a conversation chain with memory\nconversation = ConversationChain(\n    llm=llm,\n    memory=memory,\n    verbose=True\n)\n\n# First interaction\nresponse1 = conversation.predict(input=\"Hi, my name is Alice.\")\nprint(\"Response 1:\", response1)\n\n# Second interaction - the agent should remember the user's name\nresponse2 = conversation.predict(input=\"What's my name?\")\nprint(\"Response 2:\", response2)",
        "explanation": "This example demonstrates a conversational agent with memory. The ConversationBufferMemory stores the history of the conversation, allowing the agent to maintain context across multiple interactions. This enables more natural and coherent conversations, as the agent can refer back to previously mentioned information."
      },
      "output": {
        "content": "Response 1: Hello Alice! It's nice to meet you. How can I assist you today?\n\nResponse 2: Your name is Alice, as you mentioned earlier. Is there something I can help you with today, Alice?"
      }
    },
    {
      "id": "react-agent",
      "title": "ReAct Agent with Tools",
      "description": "A ReAct (Reasoning + Acting) agent that can use tools to solve complex tasks through reasoning and action steps.",
      "difficulty": "Intermediate",
      "tags": ["LangChain", "ReAct", "Tools", "Agent"],
      "code": {
        "language": "python",
        "content": "from langchain.agents import load_tools, initialize_agent, AgentType\nfrom langchain.llms import OpenAI\n\n\n# Initialize the language model\nllm = OpenAI(temperature=0)\n\n# Load tools for the agent to use\ntools = load_tools(\n    [\"serpapi\", \"llm-math\"],  # Search engine and calculator tools\n    llm=llm\n)\n\n# Initialize the ReAct agent\nagent = initialize_agent(\n    tools, \n    llm, \n    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  # ReAct pattern\n    verbose=True  # Show the agent's thought process\n)\n\n# Run the agent on a complex task\nresult = agent.run(\n    \"\"\"What was the highest temperature in San Francisco yesterday? \n    Convert that temperature from Fahrenheit to Celsius.\"\"\"\n)\n\nprint(\"Final Answer:\")\nprint(result)",
        "explanation": "This example demonstrates a ReAct agent that combines reasoning and action. The agent is given access to two tools: a search engine (serpapi) and a calculator (llm-math). When presented with a complex task, the agent breaks it down into steps, decides which tool to use at each step, and combines the results to produce a final answer. The verbose output shows the agent's thought process, including its reasoning, actions, and observations."
      },
      "output": {
        "content": "> Entering new AgentExecutor chain...\n\nI need to find the highest temperature in San Francisco yesterday, and then convert it from Fahrenheit to Celsius.\n\nAction: Search\nAction Input: \"highest temperature San Francisco yesterday\"\nObservation: According to the weather report, the highest temperature in San Francisco yesterday was 68°F.\n\nNow I need to convert 68°F to Celsius.\nThe formula is: (°F - 32) × 5/9 = °C\n\nAction: Calculator\nAction Input: (68 - 32) * 5/9\nObservation: 20.0\n\nSo 68°F is equal to 20°C.\n\n> Finished chain.\n\nFinal Answer:\nThe highest temperature in San Francisco yesterday was 68°F, which is equivalent to 20°C."
      }
    },
    {
      "id": "langgraph-workflow",
      "title": "LangGraph State Machine Workflow",
      "description": "A multi-step workflow implemented as a state machine using LangGraph, demonstrating how to build complex agent systems with explicit state management.",
      "difficulty": "Advanced",
      "tags": ["LangGraph", "State Machine", "Workflow"],
      "code": {
        "language": "python",
        "content": "from langchain.chat_models import ChatOpenAI\nfrom langchain.prompts import ChatPromptTemplate\nfrom langgraph.graph import StateGraph, END\nfrom typing import TypedDict, List\n\n\n# Define the state schema\nclass WorkflowState(TypedDict):\n    query: str\n    steps: List[str]\n    research: str\n    answer: str\n\n\n# Define node functions\ndef analyze_query(state: WorkflowState) -> WorkflowState:\n    \"\"\"Analyze the user query and determine research steps\"\"\"\n    llm = ChatOpenAI(temperature=0)\n    prompt = ChatPromptTemplate.from_template(\n        \"\"\"Analyze this query: {query}\n        Break it down into 3-5 research steps needed to answer it completely.\n        Return only a numbered list of steps.\"\"\"\n    )\n    response = llm.invoke(prompt.format(query=state[\"query\"]))\n    \n    return {\"steps\": response.content.split('\\n')}\n\n\ndef conduct_research(state: WorkflowState) -> WorkflowState:\n    \"\"\"Conduct research based on the identified steps\"\"\"\n    llm = ChatOpenAI(temperature=0)\n    steps_text = '\\n'.join(state[\"steps\"])\n    prompt = ChatPromptTemplate.from_template(\n        \"\"\"Based on these research steps:\n        {steps}\n        \n        Conduct thorough research to answer this query: {query}\n        Provide detailed findings with facts and explanations.\"\"\"\n    )\n    response = llm.invoke(\n        prompt.format(steps=steps_text, query=state[\"query\"])\n    )\n    \n    return {\"research\": response.content}\n\n\ndef formulate_answer(state: WorkflowState) -> WorkflowState:\n    \"\"\"Formulate a comprehensive answer based on research\"\"\"\n    llm = ChatOpenAI(temperature=0)\n    prompt = ChatPromptTemplate.from_template(\n        \"\"\"Based on this research:\n        {research}\n        \n        Formulate a comprehensive, well-structured answer to the query: {query}\n        Include relevant facts and clear explanations.\"\"\"\n    )\n    response = llm.invoke(\n        prompt.format(research=state[\"research\"], query=state[\"query\"])\n    )\n    \n    return {\"answer\": response.content}\n\n\n# Create the workflow graph\nworkflow = StateGraph(WorkflowState)\n\n# Add nodes\nworkflow.add_node(\"analyze\", analyze_query)\nworkflow.add_node(\"research\", conduct_research)\nworkflow.add_node(\"answer\", formulate_answer)\n\n# Add edges\nworkflow.add_edge(\"analyze\", \"research\")\nworkflow.add_edge(\"research\", \"answer\")\nworkflow.add_edge(\"answer\", END)\n\n# Set entry point\nworkflow.set_entry_point(\"analyze\")\n\n# Compile the graph\nagent = workflow.compile()\n\n# Run the workflow\nresult = agent.invoke({\n    \"query\": \"Explain how transformer neural networks revolutionized NLP\",\n    \"steps\": [],\n    \"research\": \"\",\n    \"answer\": \"\"\n})\n\nprint(\"Final Answer:\")\nprint(result[\"answer\"])",
        "explanation": "This example demonstrates a multi-step workflow implemented as a state machine using LangGraph. The workflow processes a user query through three distinct stages: analyzing the query to determine research steps, conducting the research, and formulating a comprehensive answer. Each stage is implemented as a node in the graph, with explicit transitions between stages. This approach provides clear separation of concerns, making the workflow more maintainable and easier to reason about."
      },
      "output": {
        "content": "Final Answer:\n\n# How Transformer Neural Networks Revolutionized NLP\n\nTransformer neural networks have fundamentally revolutionized Natural Language Processing (NLP), marking a paradigm shift in how machines understand and generate human language. This revolution can be understood through several key innovations and impacts.\n\n## The Attention Mechanism: A Breakthrough Innovation\n\nAt the heart of transformers lies the attention mechanism, particularly self-attention. Unlike previous recurrent neural networks (RNNs) and long short-term memory networks (LSTMs) that processed text sequentially, transformers process entire sequences simultaneously. This parallel processing allows transformers to capture relationships between words regardless of their distance in the text.\n\nThe self-attention mechanism weighs the importance of different words in relation to each other, enabling the model to focus on relevant parts of the input when producing each element of the output. This addressed the long-standing challenge of capturing long-range dependencies in text, which previous models struggled with.\n\n## Architectural Advantages\n\nTransformers introduced a highly parallelizable architecture that eliminated the sequential bottleneck of RNNs. This design offers two critical advantages:\n\n1. **Training Efficiency**: Transformers can be trained on massive datasets much faster than previous models, allowing researchers to scale up both model size and training data.\n\n2. **Scalability**: The architecture scales effectively with more computational resources, leading to increasingly powerful models like BERT, GPT, and their successors.\n\n## Pre-training and Transfer Learning\n\nTransformers enabled effective pre-training on vast amounts of unlabeled text, followed by fine-tuning for specific tasks. This approach, exemplified by models like BERT and GPT, allows:\n\n- Models to develop rich language understanding from general text before specializing\n- Excellent performance on downstream tasks with relatively little task-specific data\n- Significant improvements on nearly all NLP benchmarks with the same underlying architecture\n\n## Impact Across NLP Tasks\n\nTransformers have dramatically improved performance across virtually all NLP tasks:\n\n- **Machine Translation**: Models like Google's Transformer-based systems significantly outperform previous approaches\n- **Text Generation**: GPT and similar models can produce coherent, contextually relevant text at unprecedented quality\n- **Question Answering**: Transformer-based systems achieve human-level performance on many QA benchmarks\n- **Sentiment Analysis**: Fine-tuned transformers capture subtle nuances in text sentiment\n- **Document Summarization**: Transformers can distill long documents into coherent summaries while preserving key information\n\n## Broader Implications\n\nBeyond technical improvements, transformers have changed how we approach NLP:\n\n- They've unified previously disparate NLP tasks under common architectures\n- They've enabled practical applications that were previously theoretical\n- They've shifted research focus from task-specific architectures to scaling and improving general-purpose models\n\nThe transformer revolution continues to unfold, with each new iteration pushing the boundaries of what's possible in machine understanding and generation of human language."
      }
    },
    {
      "id": "multi-agent-system",
      "title": "Multi-Agent Collaborative System",
      "description": "A system of specialized agents that collaborate to solve complex problems, demonstrating how multiple agents can work together effectively.",
      "difficulty": "Advanced",
      "tags": ["LangChain", "Multi-Agent", "Collaboration"],
      "code": {
        "language": "python",
        "content": "from langchain.chat_models import ChatOpenAI\nfrom langchain.schema import SystemMessage, HumanMessage, AIMessage\nfrom typing import List, Dict, Any\n\n\nclass Agent:\n    \"\"\"Base class for specialized agents\"\"\"\n    def __init__(self, name: str, role: str, temperature: float = 0.5):\n        self.name = name\n        self.role = role\n        self.llm = ChatOpenAI(temperature=temperature)\n        self.system_prompt = f\"You are {name}, {role}. {self.get_instructions()}\"\n    \n    def get_instructions(self) -> str:\n        \"\"\"Return specific instructions for this agent type\"\"\"\n        return \"\"\n    \n    def process(self, input_text: str, context: List[Dict[str, Any]] = None) -> str:\n        \"\"\"Process input and return a response\"\"\"\n        messages = [SystemMessage(content=self.system_prompt)]\n        \n        # Add conversation context if provided\n        if context:\n            for message in context:\n                if message[\"role\"] == \"user\":\n                    messages.append(HumanMessage(content=message[\"content\"]))\n                elif message[\"role\"] == \"assistant\":\n                    messages.append(AIMessage(content=message[\"content\"]))\n        \n        # Add the current input\n        messages.append(HumanMessage(content=input_text))\n        \n        # Generate response\n        response = self.llm.invoke(messages)\n        return response.content\n\n\nclass ResearchAgent(Agent):\n    \"\"\"Agent specialized in research and information gathering\"\"\"\n    def get_instructions(self) -> str:\n        return \"\"\"Your job is to research topics thoroughly and provide \n        factual, comprehensive information. Focus on gathering relevant \n        facts, statistics, and expert opinions. Be thorough and objective.\n        Cite sources when possible.\"\"\"\n\n\nclass CriticAgent(Agent):\n    \"\"\"Agent specialized in critical analysis and evaluation\"\"\"\n    def get_instructions(self) -> str:\n        return \"\"\"Your job is to critically evaluate information for accuracy, \n        completeness, and potential biases. Identify gaps, inconsistencies, \n        or logical flaws. Suggest improvements and alternative perspectives.\"\"\"\n\n\nclass WriterAgent(Agent):\n    \"\"\"Agent specialized in clear, engaging writing\"\"\"\n    def get_instructions(self) -> str:\n        return \"\"\"Your job is to synthesize information into clear, \n        well-structured, and engaging content. Organize ideas logically, \n        use appropriate tone, and make complex concepts accessible \n        to the target audience.\"\"\"\n\n\nclass Coordinator:\n    \"\"\"Coordinates the multi-agent workflow\"\"\"\n    def __init__(self):\n        self.researcher = ResearchAgent(\"Research Specialist\", \"an expert researcher\")\n        self.critic = CriticAgent(\"Critical Analyst\", \"an expert critic and evaluator\")\n        self.writer = WriterAgent(\"Content Writer\", \"an expert writer\")\n    \n    def run_workflow(self, topic: str) -> Dict[str, str]:\n        \"\"\"Run the full workflow on a given topic\"\"\"\n        print(f\"Starting research on: {topic}\")\n        \n        # Step 1: Research\n        research_prompt = f\"Research the following topic thoroughly: {topic}\"\n        research_results = self.researcher.process(research_prompt)\n        print(\"Research completed.\")\n        \n        # Step 2: Critical analysis\n        critique_prompt = f\"Critically evaluate this research on '{topic}':\\n\\n{research_results}\"\n        critique = self.critic.process(critique_prompt)\n        print(\"Critical analysis completed.\")\n        \n        # Step 3: Content writing\n        writing_prompt = f\"\"\"Write a comprehensive article on '{topic}' based on:\n        \n        RESEARCH:\n        {research_results}\n        \n        CRITIQUE:\n        {critique}\n        \n        Create a well-structured, engaging article that addresses the points \n        raised in the critique and presents a balanced view of the topic.\"\"\"\n        \n        final_article = self.writer.process(writing_prompt)\n        print(\"Article writing completed.\")\n        \n        return {\n            \"topic\": topic,\n            \"research\": research_results,\n            \"critique\": critique,\n            \"article\": final_article\n        }\n\n\n# Run the multi-agent system\ncoordinator = Coordinator()\nresult = coordinator.run_workflow(\"The impact of artificial intelligence on job markets\")\n\nprint(\"\\nFINAL ARTICLE:\\n\")\nprint(result[\"article\"])",
        "explanation": "This example demonstrates a multi-agent collaborative system with three specialized agents: a researcher who gathers information, a critic who evaluates the research, and a writer who produces the final content. Each agent has a specific role and expertise, allowing them to focus on different aspects of the task. A coordinator manages the workflow, passing information between agents and ensuring that each agent's output feeds into the next stage of the process. This approach enables more sophisticated problem-solving by combining different perspectives and skills."
      },
      "output": {
        "content": "Starting research on: The impact of artificial intelligence on job markets\nResearch completed.\nCritical analysis completed.\nArticle writing completed.\n\nFINAL ARTICLE:\n\n# The Impact of Artificial Intelligence on Job Markets: A Balanced Perspective\n\nArtificial Intelligence (AI) is fundamentally reshaping global job markets, creating a complex landscape of both challenges and opportunities. This transformation extends across industries, skill levels, and geographies, with implications that are neither uniformly positive nor negative, but rather multifaceted and context-dependent.\n\n## The Transformation of Work\n\nAI technologies are automating tasks across the employment spectrum—from routine, repetitive activities to increasingly complex cognitive functions. This automation is occurring in waves, with different sectors experiencing disruption at varying rates and intensities.\n\n### Industries Experiencing Significant Change\n\n- **Manufacturing**: Robotics and AI-driven systems have already transformed production lines, with human workers increasingly focused on supervision and maintenance rather than direct production.\n\n- **Transportation**: Autonomous vehicles are poised to reshape logistics, taxi services, and delivery networks, potentially affecting millions of driving jobs worldwide.\n\n- **Financial Services**: AI algorithms now handle everything from fraud detection to investment decisions, changing the nature of work in banking, insurance, and financial analysis.\n\n- **Healthcare**: AI tools assist with diagnostics, treatment planning, and administrative tasks, augmenting rather than typically replacing healthcare professionals.\n\n- **Retail**: E-commerce algorithms and automated checkout systems are changing traditional retail employment patterns.\n\n## Job Displacement vs. Job Creation\n\nThe data suggests a nuanced reality rather than a simple narrative of job loss:\n\n### Evidence of Displacement\n\nResearch from Oxford Economics suggests that up to 20 million manufacturing jobs worldwide could be displaced by robots alone by 2030. McKinsey Global Institute estimates that between 400-800 million jobs could be automated across the global economy by 2030.\n\nDisplacement disproportionately affects:\n- Routine-task intensive occupations\n- Middle-skill jobs\n- Positions requiring limited formal education\n- Geographically concentrated industrial employment\n\n### Countervailing Job Creation\n\nHistorically, technological revolutions have ultimately created more jobs than they eliminated, though with significant transition periods. The World Economic Forum projects that while 85 million jobs may be displaced by AI and automation by 2025, 97 million new roles may emerge.\n\nNew employment opportunities include:\n\n- **AI Development and Maintenance**: Engineers, data scientists, and AI ethics specialists\n- **Human-AI Collaboration**: Roles focusing on areas where human capabilities complement AI\n- **New Industries**: Entirely new sectors emerging from AI capabilities\n- **Expanded Service Economy**: Growth in areas where human interaction remains valued\n\n## The Skills Transformation\n\nPerhaps more significant than job elimination is job transformation. Most occupations will not disappear entirely but will change in their content and required skills.\n\n### Skills Growing in Demand\n\n- **Technical AI-Related Skills**: Programming, data analysis, and machine learning expertise\n- **Human-Centric Skills**: Creativity, emotional intelligence, ethical judgment, and interpersonal communication\n- **Cognitive Flexibility**: Adaptability, critical thinking, and complex problem-solving\n- **Digital Literacy**: Basic technological competence across all sectors\n\n### The Reskilling Imperative\n\nThe scale of workforce transition required is unprecedented. According to the World Economic Forum, more than 1 billion people will need reskilling by 2030. This presents both a challenge and an opportunity for educational systems, employers, and governments.\n\n## Inequality Concerns\n\nThe benefits and costs of AI-driven labor market changes are not evenly distributed:\n\n- **Geographic Disparities**: Different regions face varying levels of disruption based on their economic structure\n- **Educational Divides**: Workers with higher education levels often adapt more readily\n- **Age Factors**: Mid-career workers may face particular challenges in transition\n- **Gender Implications**: Some heavily gendered occupations face different levels of automation risk\n\nWithout proactive policies, AI could exacerbate existing socioeconomic inequalities rather than alleviate them.\n\n## Policy Responses and Adaptation Strategies\n\nAddressing the complex impacts of AI on labor markets requires coordinated responses:\n\n### For Policymakers\n\n- **Education Reform**: Updating curricula at all levels to emphasize adaptable skills\n- **Lifelong Learning Systems**: Creating accessible continuing education opportunities\n- **Social Safety Nets**: Strengthening supports for displaced workers\n- **Targeted Economic Development**: Supporting communities facing concentrated job losses\n- **Ethical AI Governance**: Ensuring AI development considers employment impacts\n\n### For Businesses\n\n- **Strategic Workforce Planning**: Anticipating skill needs and developing internal talent\n- **Responsible Automation**: Implementing AI with consideration for workforce impacts\n- **Reskilling Programs**: Investing in employee development for changing roles\n- **Human-AI Collaboration Models**: Designing workflows that optimize both human and AI capabilities\n\n### For Individuals\n\n- **Continuous Learning**: Developing habits of ongoing skill acquisition\n- **Career Adaptability**: Building transferable skills applicable across sectors\n- **Digital Literacy**: Maintaining basic technological competence\n- **Complementary Skills**: Focusing on uniquely human capabilities\n\n## Conclusion: A Managed Transition\n\nThe impact of AI on job markets represents neither an apocalyptic scenario of mass unemployment nor a utopian vision of effortless abundance. Instead, we face a profound transition requiring thoughtful management.\n\nThe ultimate effects will depend largely on the choices made by institutions, businesses, and individuals. With proactive approaches to education, economic policy, and technological governance, AI can potentially create more fulfilling work and broadly shared prosperity. Without such measures, the transition may prove unnecessarily disruptive and inequitable.\n\nWhat remains clear is that the relationship between AI and employment is not predetermined by technology alone, but will be shaped by our collective responses to both its challenges and opportunities."
      }
    }
  ]
}
